{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b535e8-626b-4b93-9bb8-fcd80ea63a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05cdba-0735-4fa8-8f36-1cd783a2f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_texts = [\" \".join(r) for r in l3]\n",
    "job_texts    = [\" \".join(j) for j in  l4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c98899-8e62-4733-b881-56c50328643c",
   "metadata": {},
   "source": [
    "### TF-IDF Cosine Similarity\n",
    "This code computes the similarity between resumes and job descriptions using TF-IDF vectorization. Each resume and job description pair is transformed into TF-IDF vectors, and the row-wise cosine similarity is calculated to measure how closely they match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b50d9a-73aa-47bf-9cc7-2035dc098386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n",
    "\n",
    "def compute_tfidf_cosine(resume_texts, job_texts):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    combined   = resume_texts + job_texts\n",
    "    tfidf_matrix = vectorizer.fit_transform(combined)\n",
    "    n = len(resume_texts)\n",
    "\n",
    "    resume_tfidf = tfidf_matrix[:n]\n",
    "    job_tfidf    = tfidf_matrix[n:]\n",
    "\n",
    "    tfidf_cosine = [\n",
    "        float(cosine_similarity(resume_tfidf[i], job_tfidf[i])[0][0])\n",
    "        for i in range(n)\n",
    "    ]\n",
    "\n",
    "    return tfidf_cosine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f44210d-c47d-4e3c-bd65-c638a45a2378",
   "metadata": {},
   "source": [
    "### Jaccard Similarity\n",
    "This code computes the Jaccard similarity between tokenized resumes (`l3`) and job descriptions (`l4`). Each text is converted to a set of words, and the similarity is calculated as the size of the intersection divided by the size of the union for each resume–job pair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beafcb46-d1da-4abe-a47f-5a616fdcf882",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_sets = [set(r) for r in l3]\n",
    "job_sets    = [set(j) for j in l4]\n",
    "\n",
    "def compute_jaccard(resume_sets, job_sets):\n",
    "    def jaccard_sim(a, b):\n",
    "        return len(a & b) / len(a | b) if len(a | b) > 0 else 0\n",
    "\n",
    "    jaccard = [\n",
    "        jaccard_sim(a, b)\n",
    "        for a, b in zip(resume_sets, job_sets)\n",
    "    ]\n",
    "\n",
    "    return jaccard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f095ba-5ef5-4deb-b3f2-d4d0cda38b2d",
   "metadata": {},
   "source": [
    "### Sentence-BERT Cosine Similarity\n",
    "This code uses the `all-MiniLM-L6-v2` SentenceTransformer model to compute semantic similarity between resumes and job descriptions. It encodes each text into embeddings and calculates cosine similarity for corresponding resume–job pairs to capture meaning-based matches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f884f1f2-0cac-4dd0-aa89-6cd034594a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "def compute_sentencebert_cosine(resume_texts, job_texts):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    emb_r = model.encode(resume_texts, convert_to_tensor=True)\n",
    "    emb_l = model.encode(job_texts, convert_to_tensor=True)\n",
    "\n",
    "    pairwise_similarities = [\n",
    "        util.cos_sim(emb_r[i], emb_l[i]).item()\n",
    "        for i in range(min(len(resume_texts), len(job_texts)))\n",
    "    ]\n",
    "\n",
    "    return pairwise_similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eb6438-18a1-43d6-b320-d0d016dfec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_cosine       = compute_tfidf_cosine(resume_texts, job_texts)\n",
    "jaccard            = compute_jaccard([set(r) for r in l3], [set(j) for j in l4])\n",
    "pairwise_similarities = compute_sentencebert_cosine(resume_texts, job_texts)\n",
    "features_df = pd.DataFrame()\n",
    "features_df[\"tfidf_cosine\"] = tfidf_cosine\n",
    "features_df[\"jaccard\"] = jaccard\n",
    "features_df[\"bert_sim\"] = pairwise_similarities\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544ccdb6-7875-4110-8d57-2e99057f6bfd",
   "metadata": {},
   "source": [
    "### Skill Overlap Features\n",
    "The `skill_features` function computes row-wise skill-based features between tokenized resumes (`l3`) and job descriptions (`l4`). It calculates the number of overlapping skills, the percentage of required skills present, and the count of missing skills for each resume–job pair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13798af1-2482-49cb-ba60-50cc9db58427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_skill_features(l3, l4):\n",
    "    def skill_features(resume_tokens, job_tokens):\n",
    "        rset = set(resume_tokens or [])\n",
    "        jset = set(job_tokens or [])\n",
    "\n",
    "        overlap = rset & jset\n",
    "        overlap_count = len(overlap)\n",
    "\n",
    "        job_count = len(jset)\n",
    "        percent_required_present = overlap_count / job_count if job_count > 0 else 0.0\n",
    "\n",
    "        missing_skill_count = job_count - overlap_count\n",
    "\n",
    "        return overlap_count, percent_required_present, missing_skill_count\n",
    "\n",
    "    return [skill_features(r, j) for r, j in zip(l3, l4)]\n",
    "\n",
    "\n",
    "overlap_count, percent_required_present, missing_skill_count = zip(*compute_skill_features(l3, l4))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415b78ed-4fd8-4af4-b4f1-fbc43c888f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_df[\"overlap_count\"]= overlap_count\n",
    "features_df[\"percent_required_present\"]= percent_required_present\n",
    "features_df[\"missing_skill_count\"]= missing_skill_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef88d11e-13fc-48c2-a8e2-c7b335b5f6b3",
   "metadata": {},
   "source": [
    "### Structural Text Features\n",
    "This code extracts structural features from tokenized resumes (`l3`) and job descriptions (`l4`). Features include the lengths of resumes and jobs, the overlap ratio of unique tokens, and the difference in token counts, which are added to `features_df` for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f970765b-9246-4205-8e24-e35b22205508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_structural_features(l3, l4):\n",
    "    resume_length    = [len(r) for r in l3]\n",
    "    job_length       = [len(j) for j in l4]\n",
    "    overlap_ratio    = [\n",
    "        len(set(r) & set(j)) / len(set(r) | set(j)) if len(set(r) | set(j)) > 0 else 0\n",
    "        for r, j in zip(l3, l4)\n",
    "    ]\n",
    "    token_count_diff = [abs(len(r) - len(j)) for r, j in zip(l3, l4)]\n",
    "    return resume_length, job_length, overlap_ratio, token_count_diff\n",
    "\n",
    "resume_length, job_length, overlap_ratio, token_count_diff = compute_structural_features(l3, l4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aebc5d-e80e-4d6d-b009-2598d9c1dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "features_df[\"resume_length\"]= resume_length\n",
    "features_df[\"job_length\"]= job_length\n",
    "features_df[\"overlap_ratio\"]= overlap_ratio\n",
    "features_df[\"token_count_diff\"]=token_count_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab906fd-3d94-468c-a3f9-d8767f32ce31",
   "metadata": {},
   "source": [
    "# now we have implemented ml model on ml_implementation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e92702-7b78-4b18-b89a-5ad043549691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
