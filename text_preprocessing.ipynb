{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8748b616-d4e6-44f5-89bc-4b25de121f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b20a8b2-568d-4c6a-9bd8-4a457a311210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"resume_job_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7bd6f79-21f2-4333-b7b7-60000a26b3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f4fb57-2c03-4590-b5c5-4f97bd3114ce",
   "metadata": {},
   "source": [
    "## This is how our dataset looks like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3475525b-a802-4672-a2db-f80eb7e9e0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>resume</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst needed with experience in SQL, Ex...</td>\n",
       "      <td>Experienced professional skilled in sql, excel...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist needed with experience in Stati...</td>\n",
       "      <td>Experienced professional skilled in statistics...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Software Engineer needed with experience in Sy...</td>\n",
       "      <td>Experienced professional skilled in system des...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML Engineer needed with experience in Python, ...</td>\n",
       "      <td>Experienced professional skilled in python, co...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Software Engineer needed with experience in RE...</td>\n",
       "      <td>Experienced professional skilled in rest apis,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     job_description  \\\n",
       "0  Data Analyst needed with experience in SQL, Ex...   \n",
       "1  Data Scientist needed with experience in Stati...   \n",
       "2  Software Engineer needed with experience in Sy...   \n",
       "3  ML Engineer needed with experience in Python, ...   \n",
       "4  Software Engineer needed with experience in RE...   \n",
       "\n",
       "                                              resume  match_score  \n",
       "0  Experienced professional skilled in sql, excel...            4  \n",
       "1  Experienced professional skilled in statistics...            4  \n",
       "2  Experienced professional skilled in system des...            5  \n",
       "3  Experienced professional skilled in python, co...            4  \n",
       "4  Experienced professional skilled in rest apis,...            5  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c71d3d-346d-4898-9270-937572955ed2",
   "metadata": {},
   "source": [
    "### Text Cleaning Function\n",
    "The `clean_text(df)` function converts all text in job descriptions and resumes to lowercase, removes punctuation, and replaces multiple spaces or newlines with a single space. This ensures the text data is clean and uniform for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b642b58-d70c-4669-a933-5fc28180292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df):\n",
    "    #extracting job descriptions and resumes from dataframe\n",
    "    job_desc=df[\"job_description\"]\n",
    "    resume=df[\"resume\"]\n",
    "    \n",
    "    #converting all text to lowercase \n",
    "    job_desc_lower=[t.lower() for t in job_desc]\n",
    "    resume_lower=[t.lower() for t in resume]\n",
    "\n",
    "    #removing punctuation by replacing it with spaces\n",
    "    pattern = r'[{}]'.format(re.escape(string.punctuation))\n",
    "    job_desc_clean = [re.sub(pattern, ' ', t) for t in job_desc_lower]\n",
    "    resume_clean   = [re.sub(pattern, ' ', t) for t in resume_lower]\n",
    "\n",
    "    #replacing  multiple spaces/tabs/newlines with a single space and trim ends\n",
    "    pattern=r'\\s+'\n",
    "    job_desc_clean = [re.sub(pattern, ' ', t).strip() for t in job_desc_clean]\n",
    "    resume_clean   = [re.sub(pattern, ' ', t).strip() for t in resume_clean]\n",
    "\n",
    "    df[\"job_description\"]=job_desc_clean\n",
    "    df[\"resume\"]=resume_clean\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40db3ec5-a9eb-4ea4-8df6-97484e12b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=clean_text(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32599e0d-66bc-44f3-b5f8-daf2aab36219",
   "metadata": {},
   "source": [
    "### Tokenization and Stopword Removal\n",
    "The `tokenize_and_remove_stopwords(df)` function tokenizes job descriptions and resumes into individual words, removes English stopwords, and keeps only alphabetic tokens. This step helps focus on meaningful words for text analysis or model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d20d452c-704a-4bfb-addd-2bf9285ebfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")   \n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "def tokenize_and_remove_stopwords(df):\n",
    "\n",
    "    job_desc=df[\"job_description\"]\n",
    "    resume=df[\"resume\"]\n",
    "  \n",
    "    tokens_job_desc = [word_tokenize(t) for t in job_desc]\n",
    "    tokens_resume   = [word_tokenize(t) for t in resume]\n",
    "\n",
    "    # load English stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    # filter out stopwords + keep only alphabetic tokens\n",
    "    filtered_job_desc = [[w for w in tokens if w.isalpha() and w not in stop_words]\n",
    "                         for tokens in tokens_job_desc]\n",
    "    filtered_resume   = [[w for w in tokens if w.isalpha() and w not in stop_words]\n",
    "                         for tokens in tokens_resume]\n",
    "\n",
    "    return filtered_job_desc, filtered_resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43a9ac9-d335-469b-b7d6-4059a7349fc5",
   "metadata": {},
   "source": [
    "### Lemmatization of Tokens\n",
    "The `lemmatize_tokens(job_tokens, resume_tokens)` function applies lemmatization to tokenized job descriptions and resumes, converting words to their base form. This reduces word variations and helps in consistent text analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74997e85-134a-4971-913e-001dc7822341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens(job_tokens, resume_tokens):\n",
    "   \n",
    "    lemmatized_job_desc = [[lemmatizer.lemmatize(w) for w in tokens]\n",
    "                           for tokens in job_tokens]\n",
    "    lemmatized_resume   = [[lemmatizer.lemmatize(w) for w in tokens]\n",
    "                           for tokens in resume_tokens]\n",
    "    \n",
    "    return lemmatized_job_desc, lemmatized_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42abef0a-3461-4f41-9e51-d3f87624b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1,l2=tokenize_and_remove_stopwords(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff6c353a-900d-4bb6-a3d5-1246af4d2ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l3,l4=lemmatize_tokens(l1,l2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e085b0f-3e3a-4bba-baa8-119182ce8dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"job_description\"]=l4\n",
    "df[\"resume\"]=l3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60be451-ea85-492c-a9ac-f71593824ed7",
   "metadata": {},
   "source": [
    "## final dataset after removing all stop wrods converting all text into lower case and then doing  Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c58f556-dd19-4911-9da3-bfe976a3629d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>resume</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[experienced, professional, skilled, sql, exce...</td>\n",
       "      <td>[data, analyst, needed, experience, sql, excel...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[experienced, professional, skilled, statistic...</td>\n",
       "      <td>[data, scientist, needed, experience, statisti...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[experienced, professional, skilled, system, d...</td>\n",
       "      <td>[software, engineer, needed, experience, syste...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[experienced, professional, skilled, python, c...</td>\n",
       "      <td>[ml, engineer, needed, experience, python, com...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[experienced, professional, skilled, rest, api...</td>\n",
       "      <td>[software, engineer, needed, experience, rest,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     job_description  \\\n",
       "0  [experienced, professional, skilled, sql, exce...   \n",
       "1  [experienced, professional, skilled, statistic...   \n",
       "2  [experienced, professional, skilled, system, d...   \n",
       "3  [experienced, professional, skilled, python, c...   \n",
       "4  [experienced, professional, skilled, rest, api...   \n",
       "\n",
       "                                              resume  match_score  \n",
       "0  [data, analyst, needed, experience, sql, excel...            4  \n",
       "1  [data, scientist, needed, experience, statisti...            4  \n",
       "2  [software, engineer, needed, experience, syste...            5  \n",
       "3  [ml, engineer, needed, experience, python, com...            4  \n",
       "4  [software, engineer, needed, experience, rest,...            5  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb126a8-5dcb-42d2-81a7-3106b70db5af",
   "metadata": {},
   "source": [
    "##  Since machine learning models cannot process raw text directly, we convert the cleaned text into numerical representations that the models can understand. This feature conversion is implemented in the convert_features.ipynb ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2268ba9-c370-4044-b364-f6d770e53827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
